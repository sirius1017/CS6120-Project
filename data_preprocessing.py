import json
from typing import List, Dict
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from langchain_huggingface import HuggingFaceEmbeddings # ä½¿ç”¨huggingfaceè€Œä¸ç”¨openaiï¼Œè¿™æ ·å¯ä»¥ç›´æŽ¥æŠŠæ¨¡åž‹ä¸‹è½½åˆ°æœ¬åœ°ä½¿ç”¨ï¼Œä¸ç”¨call api
import os
import shutil
from typing import Dict, List
from langchain_core.prompts import PromptTemplate
from transformers import pipeline
from tqdm import tqdm
from langchain_huggingface import HuggingFacePipeline
from dotenv import load_dotenv

#è°ƒä¼˜ï¼šencoderçŽ°åœ¨ç”¨çš„æ˜¯HuggingFaceEmbeddingsï¼Œå¯èƒ½å¯ä»¥æ¢ä¸€ä¸‹è¯•è¯•ï¼Ÿ
#åŠ é€Ÿï¼šbatch embedding, batch write to chroma db
#thresholdï¼štestç”¨ï¼Œæœ€åŽéœ€è¦åŽ»æŽ‰
#è®¡æ—¶

def summarize_instructions(recipes, path):
    summarization_prompt = PromptTemplate.from_template("""
        You are a recipe assistant. Your job is to summarize the following recipe instructions.

        Focus on:
        - The main **cooking methods**
        - Important **kitchen tools**
        - Key preparation or serving steps

        Instructions:
        {instructions}

        Return a concise summary that highlights the above elements.
        """)
    
    # Set up HuggingFace summarizer model 
    # device = 0, run gpu
    flan_pipeline = pipeline("text2text-generation", model="google/flan-t5-base", device=0, max_length=128)

    # Wrap it for LangChain compatibility
    flan_llm = HuggingFacePipeline(pipeline=flan_pipeline)
    chain = summarization_prompt | flan_llm
    
    summaries = []
    for recipe in tqdm(recipes):
        raw_steps = " ".join([step["text"] for step in recipe.get("instructions", [])])
        if not raw_steps.strip():
            continue

        try:
            summary = chain.invoke(input={"instructions": raw_steps})
            summaries.append({
                "id": recipe.get("id", ""),
                "summary": summary
            })
        except Exception as e:
            print(f"âŒ Failed for {recipe.get('id')}: {e}")

    # Save to JSON
    with open(path, "w", encoding="utf-8") as f:
        json.dump(summaries, f, ensure_ascii=False, indent=2)

    print(f"âœ… Saved {len(summaries)} summaries to {path}")

def load_or_create_vectorstore(docs, embeddings, persist_dir):
    if os.path.exists(os.path.join(persist_dir, "chroma.sqlite3")):
        print(f"âœ… Loading existing vectorstore from: {persist_dir}")
        return Chroma(
            embedding_function=embeddings,
            persist_directory=persist_dir
        )
    else:
        print(f"ðŸ“š Creating and saving new vectorstore to: {persist_dir}")
        return Chroma.from_documents(
            documents=docs,
            embedding=embeddings,
            persist_directory=persist_dir
        )

def prepare_documents(recipes: List[dict]) -> List:
    title_docs = []
    ingredients_docs = []
    instruction_docs = []

    for recipe in recipes:
        title = recipe.get("title", "Untitled")

        raw_ings = recipe.get("ingredients", [])

        # # åªæå–å„ingredientçš„ç¬¬ä¸€ä¸ªå•è¯
        # # å­˜åœ¨çš„é—®é¢˜ eg. "candies, semisweet chocolate"
        first_words = [i["text"].split(",")[0].lower() for i in raw_ings if "text" in i and i["text"]]
        ingredients = ";".join(sorted(first_words))

        recipe_id = recipe.get("id", "")
        metadata = { 
            "id": recipe_id
        }

        title_docs.append(Document(page_content=title, metadata=metadata)) 
        ingredients_docs.append(Document(page_content=ingredients, metadata=metadata))

        # ----- Step-Level Instructions -----
        instruction_texts = [step['text'] for step in recipe.get('instructions', [])]
        for idx, text in enumerate(instruction_texts):
            if text.strip():
                instruction_docs.append(Document(
                    page_content=text.strip(),
                    metadata={
                        "id": recipe_id,
                        "step": idx
                    }
                ))

        # instruction_texts = [step['text'] for step in recipe.get('instructions', [])]
        # full_instructions = " ".join(instruction_texts)
        # if full_instructions.strip():  # skip empty
        #     instruction_docs.append(Document(page_content=full_instructions, metadata=metadata))

    return title_docs, ingredients_docs, instruction_docs


def load_recipes_from_json(file_path: str) -> List[Dict]:
    """Load and parse recipes from a local JSON file."""
    with open(file_path, 'r', encoding='utf-8') as f:
        recipes = json.load(f)
    return recipes


def ingest_to_chroma(json_path="./recipes.json", 
                    persist_dir_title="./chroma_title", 
                    persist_dir_ingredients="./chroma_ingredients",
                    persist_dir_instructions="./chroma_instructions",
                    threshold=-1):
    """Main pipeline: load -> format -> embed -> save to ChromaDB."""

    print("ðŸ” Loading recipes...")

    # # å…ˆåˆ é™¤æ—§å‘é‡åº“
    # for path in [persist_dir_title, persist_dir_ingredients]:
    #     if os.path.exists(path):
    #         print(f"âš ï¸ Found existing directory {path}. Removing it before regeneration...")
    #         shutil.rmtree(path)

    recipes = load_recipes_from_json(json_path)
    if threshold > 0:
        recipes = recipes[:threshold]

    title_docs, ingredients_docs, instructions_docs = prepare_documents(recipes)

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        cache_folder="./hf_cache",
        model_kwargs={"device": "cuda"}, ###################### GPU
        encode_kwargs={"batch_size": 128, "normalize_embeddings": True}
    )

    print("ðŸ“š Embedding titles...")
    title_store = load_or_create_vectorstore(title_docs, embeddings, persist_dir_title)

    print("ðŸ¥¬ Embedding ingredients...")
    ingredients_store = load_or_create_vectorstore(ingredients_docs, embeddings, persist_dir_ingredients)

    print("ðŸ¥¬ Embedding instructions...")
    instructions_store = load_or_create_vectorstore(instructions_docs, embeddings, persist_dir_instructions)


if __name__ == "__main__":
    with open("./recipes.json", "r", encoding="utf-8") as f:
        recipes = json.load(f)
    print(f"ä¸€å…± {len(recipes)} æ¡èœè°±")

    # # ingest_to_chroma(threshold=100) #è¯•è¿è¡Œè½¬æ¢ä¸ºembeddings
    ingest_to_chroma() # recipes--> embeddings
    # summarize_instructions(recipes, "./summarized_instructions.json")

